"""
–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –î–∞–Ω–Ω—ã—Ö –¥–ª—è YOLOv11-seg.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç 100% —Ñ–∞–π–ª–æ–≤ –∏–∑ backgrounds + –¥–æ–±–∞–≤–ª—è–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã.
"""

import cv2
import numpy as np
import random
import yaml
from pathlib import Path
from tqdm import tqdm
import config


def generate_gradient(w, h):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç (–õ–∏–Ω–µ–π–Ω—ã–π –∏–ª–∏ –î–∏–∞–≥–æ–Ω–∞–ª—å–Ω—ã–π).
    –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –í–ï–†–°–ò–Ø (NumPy Vectorization).
    –†–∞–±–æ—Ç–∞–µ—Ç –≤ 100 —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ —Ü–∏–∫–ª–æ–≤.
    """
    # 1. –í—ã–±–æ—Ä —Ü–≤–µ—Ç–æ–≤ (–æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–≤–æ—é –ª–æ–≥–∏–∫—É)
    if random.random() < 0.5:
        c1 = np.random.randint(200, 256, (3,))  # –°–≤–µ—Ç–ª—ã–π 1
        c2 = np.random.randint(150, 230, (3,))  # –°–≤–µ—Ç–ª—ã–π 2
    else:
        c1 = np.random.randint(50, 120, (3,))  # –¢–µ–º–Ω—ã–π 1
        c2 = np.random.randint(10, 80, (3,))  # –¢–µ–º–Ω—ã–π 2

    # 2. –°–æ–∑–¥–∞–µ–º —Å–µ—Ç–∫—É –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ alpha (–æ—Ç 0.0 –¥–æ 1.0)
    # –í–º–µ—Å—Ç–æ —Ü–∏–∫–ª–æ–≤ —Å–æ–∑–¥–∞–µ–º –º–∞—Å—Å–∏–≤—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç

    # –¢–∏–ø –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞
    rnd_type = random.random()

    if rnd_type < 0.7:
        # –õ–∏–Ω–µ–π–Ω—ã–π (–í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π –∏–ª–∏ –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π)
        if random.random() < 0.5:
            # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π: –º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ –≤—ã—Å–æ—Ç–µ (axis 0)
            # Shape: (h, 1, 1) ‚Äî —á—Ç–æ–±—ã –±—Ä–æ–¥–∫–∞—Å—Ç–∏—Ç—å –Ω–∞ —à–∏—Ä–∏–Ω—É –∏ –∫–∞–Ω–∞–ª—ã
            alpha = np.linspace(0, 1, h).reshape(h, 1, 1)
        else:
            # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π: –º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ —à–∏—Ä–∏–Ω–µ (axis 1)
            # Shape: (1, w, 1)
            alpha = np.linspace(0, 1, w).reshape(1, w, 1)
    else:
        # –î–∏–∞–≥–æ–Ω–∞–ª—å–Ω—ã–π (–∏–º–∏—Ç–∞—Ü–∏—è —Ç–æ–≥–æ, —á—Ç–æ —É —Ç–µ–±—è –±—ã–ª–æ (i/h + j/w)/2)
        # –°–æ–∑–¥–∞–µ–º –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π –≤–µ–∫—Ç–æ—Ä Y –∏ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π X
        Y = np.linspace(0, 1, h).reshape(h, 1, 1)
        X = np.linspace(0, 1, w).reshape(1, w, 1)
        # –°–∫–ª–∞–¥—ã–≤–∞–µ–º (NumPy —Å–∞–º —Ä–∞—Å—à–∏—Ä–∏—Ç –∏—Ö –¥–æ –º–∞—Ç—Ä–∏—Ü—ã h x w)
        alpha = (Y + X) / 2.0

    # 3. –ú–∞–≥–∏—è NumPy (Broadcasting)
    # alpha –∏–º–µ–µ—Ç —Ñ–æ—Ä–º—É (h, w, 1) (–∏–ª–∏ –±—Ä–æ–¥–∫–∞—Å—Ç–∏—Ç—Å—è –¥–æ –Ω–µ—ë)
    # c1 –∏ c2 –∏–º–µ—é—Ç —Ñ–æ—Ä–º—É (3,)
    # NumPy —Å–∞–º —É–º–Ω–æ–∂–∏—Ç –∫–∞–∂–¥—ã–π –ø–∏–∫—Å–µ–ª—å –Ω–∞ —Ü–≤–µ—Ç.
    img = (1.0 - alpha) * c1 + alpha * c2

    return img.astype(np.uint8)

def get_yolo_polygon(mask, img_w, img_h):
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    polygons = []
    for cnt in contours:
        if cv2.contourArea(cnt) < 50: continue
        epsilon = 0.002 * cv2.arcLength(cnt, True)
        approx = cv2.approxPolyDP(cnt, epsilon, True)
        if len(approx) < 4: continue
        points = []
        for point in approx:
            x, y = point[0]
            nx = max(0, min(1, x / img_w))
            ny = max(0, min(1, y / img_h))
            points.append(f"{nx:.6f} {ny:.6f}")
        polygons.append(" ".join(points))
    return polygons

def smart_resize(img, w, h):
    h_orig, w_orig = img.shape[:2]
    if w > w_orig or h > h_orig: return cv2.resize(img, (w, h), interpolation=cv2.INTER_LANCZOS4)
    else: return cv2.resize(img, (w, h), interpolation=cv2.INTER_AREA)

def apply_random_color(img_rgba):
    if random.random() < config.GEN_COLOR_PROB:
        color = np.random.randint(0, 256, (3,), dtype=np.uint8)
        gray = cv2.cvtColor(img_rgba[:, :, :3], cv2.COLOR_BGR2GRAY) / 255.0
        result = img_rgba.copy()
        for c in range(3):
            colored_layer = np.ones_like(gray) * color[c]
            result[:, :, c] = (colored_layer * gray).astype(np.uint8)
        return result
    return img_rgba

def apply_edge_corruption(img_rgba):
    if random.random() > getattr(config, 'GEN_PROB_EDGE_CORRUPTION', 0.5): return img_rgba
    b, g, r, a = cv2.split(img_rgba)
    ksize = random.choice([3, 5])
    kernel = np.ones((ksize, ksize), np.uint8)
    if random.random() < 0.5: a = cv2.erode(a, kernel, iterations=1)
    else: a = cv2.dilate(a, kernel, iterations=1)
    if random.random() < 0.5: a = cv2.GaussianBlur(a, (3, 3), 0)
    return cv2.merge((b, g, r, a))

def process_single_image(bg, wm_original, index, base_dir):
    """–õ–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ —Ñ–æ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è"""
    split = "train" if random.random() < config.GEN_TRAIN_RATIO else "val"
    h_bg, w_bg = bg.shape[:2]
    filename = f"syn_{index:06d}" # 6 —Ü–∏—Ñ—Ä

    # === NEGATIVE SAMPLE ===
    if random.random() < config.GEN_PROB_NEGATIVE:
        cv2.imwrite(str(base_dir / 'images' / split / f"{filename}.jpg"), bg)
        open(base_dir / 'labels' / split / f"{filename}.txt", "w").close()
        return

    wm_curr = wm_original.copy()
    is_hard_mode = random.random() > config.GEN_PROB_EASY_MODE

    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    if random.random() < config.GEN_ROTATION_PROB:
        wm_curr = cv2.rotate(wm_curr, cv2.ROTATE_90_CLOCKWISE)

    if is_hard_mode and random.random() < config.GEN_INVERT_PROB:
        wm_curr[:, :, :3] = cv2.bitwise_not(wm_curr[:, :, :3])

    scale_ratio = random.uniform(*config.GEN_SCALE_RANGE)
    h_wm, w_wm = wm_curr.shape[:2]
    new_w = int(w_bg * scale_ratio)
    new_h = int(h_wm * (new_w / w_wm))

    if new_h > h_bg: new_h = int(h_bg * 0.9); new_w = int(w_wm * (new_h / h_wm))
    if new_w < 10: return

    wm_resized = smart_resize(wm_curr, new_w, new_h)

    if is_hard_mode:
        wm_resized = apply_random_color(wm_resized)
        if random.random() < config.GEN_BLUR_PROB:
            k = random.choice([3, 5])
            wm_resized = cv2.GaussianBlur(wm_resized, (k, k), 0)
        wm_resized = apply_edge_corruption(wm_resized)
        opacity = random.uniform(*config.GEN_OPACITY_RANGE)
    else:
        opacity = random.uniform(0.7, 1.0)

    # –ù–∞–ª–æ–∂–µ–Ω–∏–µ
    wm_rgb = wm_resized[:, :, :3]
    wm_alpha = wm_resized[:, :, 3] / 255.0
    wm_alpha = wm_alpha * opacity

    y_off = random.randint(0, h_bg - new_h)
    x_off = random.randint(0, w_bg - new_w)

    roi = bg[y_off:y_off+new_h, x_off:x_off+new_w]
    for c in range(3):
        roi[:, :, c] = (1.0 - wm_alpha) * roi[:, :, c] + \
                       wm_alpha * wm_rgb[:, :, c]
    bg[y_off:y_off+new_h, x_off:x_off+new_w] = roi

    # –ú–∞—Å–∫–∞
    mask_binary = np.zeros((h_bg, w_bg), dtype=np.uint8)
    wm_shape = (wm_resized[:, :, 3] > 10).astype(np.uint8) * 255
    mask_binary[y_off:y_off+new_h, x_off:x_off+new_w] = wm_shape

    polygons = get_yolo_polygon(mask_binary, w_bg, h_bg)

    if polygons:
        cv2.imwrite(str(base_dir / 'images' / split / f"{filename}.jpg"), bg)
        with open(base_dir / 'labels' / split / f"{filename}.txt", "w") as f:
            for poly in polygons:
                f.write(f"0 {poly}\n")

def generate_dataset():
    # –ü—Ä–æ–≤–µ—Ä–∫–∏
    if not config.WATERMARK_SOURCE.exists():
        print(f"‚ùå –ù–µ—Ç —Ñ–∞–π–ª–∞ {config.WATERMARK_SOURCE}")
        return
    bg_files = list(config.BACKGROUNDS_DIR.glob("*.jpg"))
    if not bg_files:
        print(f"‚ùå –ù–µ—Ç —Ñ–æ–Ω–æ–≤. –ó–∞–ø—É—Å—Ç–∏ 0_download_backgrounds.py")
        return

    base_dir = config.TRAIN_DATASET_DIR
    for split in ['train', 'val']:
        (base_dir / 'images' / split).mkdir(parents=True, exist_ok=True)
        (base_dir / 'labels' / split).mkdir(parents=True, exist_ok=True)

    # –ì—Ä—É–∑–∏–º –∏—Å—Ö–æ–¥–Ω–∏–∫
    wm_original = cv2.imread(str(config.WATERMARK_SOURCE), cv2.IMREAD_UNCHANGED)
    if wm_original.shape[2] == 3:
        b, g, r = cv2.split(wm_original)
        alpha = np.ones_like(b) * 255
        wm_original = cv2.merge((b, g, r, alpha))

    # –õ–µ—á–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–∏–∫–∞
    dil_size = getattr(config, 'GEN_SOURCE_REPAIR_DILATION', 0)
    if dil_size > 0:
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dil_size, dil_size))
        b,g,r,a = cv2.split(wm_original)
        a = cv2.dilate(a, kernel, iterations=1)
        b = cv2.dilate(b, kernel, iterations=1)
        g = cv2.dilate(g, kernel, iterations=1)
        r = cv2.dilate(r, kernel, iterations=1)
        wm_original = cv2.merge((b,g,r,a))

    # 1. –°—á–∏—Ç–∞–µ–º, —Å–∫–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
    total_real = len(bg_files)
    total_solid = int(total_real * config.GEN_EXTRA_SOLID_PERCENT)
    total_count = total_real + total_solid

    print(f"üöÄ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
    print(f"   üì∏ –†–µ–∞–ª—å–Ω—ã–µ —Ñ–æ–Ω—ã: {total_real}")
    print(f"   üé® –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã:     {total_solid}")
    print(f"   ‚àë  –ò—Ç–æ–≥–æ:         {total_count}")

    counter = 0

    # 2. –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –í–°–ï–ú —Ä–µ–∞–ª—å–Ω—ã–º —Ñ–æ—Ç–æ
    print("   [1/2] –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —Ñ–æ–Ω–æ–≤...")
    for bg_path in tqdm(bg_files):
        bg = cv2.imread(str(bg_path))
        if bg is None: continue
        process_single_image(bg, wm_original, counter, base_dir)
        counter += 1

    # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
    print("   [2/2] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤...")
    for _ in tqdm(range(total_solid)):
        h = random.randint(600, 1024)
        w = random.randint(600, 1024)
        bg = generate_gradient(w, h)
        process_single_image(bg, wm_original, counter, base_dir)
        counter += 1

    # data.yaml
    yaml_data = {
        'path': base_dir.absolute().as_posix(),
        'train': 'images/train',
        'val': 'images/val',
        'names': {0: 'watermark'}
    }
    with open(base_dir / "data.yaml", "w") as f:
        yaml.dump(yaml_data, f, sort_keys=False)

    print(f"\n‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –í—Å–µ–≥–æ —Å–æ–∑–¥–∞–Ω–æ {counter} –ø—Ä–∏–º–µ—Ä–æ–≤.")

if __name__ == "__main__":
    generate_dataset()