"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU (NVIDIA CUDA) –¥–ª—è PyTorch.
"""

import sys
import torch
import platform

def check_gpu():
    print("="*40)
    print(f"üêç Python: {sys.version.split()[0]} ({platform.system()})")
    print(f"üî• PyTorch: {torch.__version__}")
    print("="*40)

    if torch.cuda.is_available():
        print("‚úÖ CUDA AVAILABLE! –í–∏–¥–µ–æ–∫–∞—Ä—Ç–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞.")
        device_count = torch.cuda.device_count()
        print(f"üî¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU: {device_count}")
        
        for i in range(device_count):
            name = torch.cuda.get_device_name(i)
            mem = torch.cuda.get_device_properties(i).total_memory / 1e9
            print(f"   üëâ GPU {i}: {name} ({mem:.2f} GB VRAM)")
            
        print("\nüß™ –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–≥–æ–Ω —Ç–µ–Ω–∑–æ—Ä–æ–≤...")
        try:
            x = torch.rand(5, 3).cuda()
            print("   ‚úÖ –¢–µ–Ω–∑–æ—Ä —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –≤ VRAM!")
            print(f"   –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Ç–µ–Ω–∑–æ—Ä–∞: {x.device}")
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å VRAM: {e}")

    else:
        print("‚ö†Ô∏è  CUDA NOT AVAILABLE.")
        print("   –†–∞–±–æ—Ç–∞–µ–º –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–µ (CPU). –≠—Ç–æ –±—É–¥–µ—Ç –º–µ–¥–ª–µ–Ω–Ω–æ.")
        print("   –ï—Å–ª–∏ —É —Ç–µ–±—è NVIDIA –∫–∞—Ä—Ç–∞:")
        print("   1. –ü—Ä–æ–≤–µ—Ä—å –¥—Ä–∞–π–≤–µ—Ä—ã.")
        print("   2. –£–±–µ–¥–∏—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–∏–ª PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA:")
        print("      pip install --force-reinstall torch torchvision --index-url https://download.pytorch.org/whl/cu124")

    print("="*40)

if __name__ == "__main__":
    check_gpu()